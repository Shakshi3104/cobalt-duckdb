import os

from typing import List, Union, Optional
from pathlib import Path

import numpy as np
import pandas as pd

from copy import deepcopy
from dotenv import load_dotenv
from loguru import logger
from tqdm import tqdm

import sentence_transformers as st

import voyager

from model.search.base import BaseSearchClient
from model.utils.timer import stop_watch


def array_to_string(array: np.ndarray) -> str:
    """
    np.ndarrayã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹

    Parameters
    ----------
    array:
        np.ndarray

    Returns
    -------
    array_string:
        str
    """
    array_string = f"{array.tolist()}"
    return array_string


class RuriEmbedder:
    def __init__(self, model: Optional[st.SentenceTransformer] = None):

        load_dotenv()

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆ
        self.model_dir = Path("models/ruri")
        model_filepath = self.model_dir / "ruri-large"

        # ãƒ¢ãƒ‡ãƒ«
        if model is None:
            if model_filepath.exists():
                logger.info(f"ğŸš¦ [RuriEmbedder] load ruri-large from local path: {model_filepath}")
                self.model = st.SentenceTransformer(str(model_filepath))
            else:
                logger.info(f"ğŸš¦ [RuriEmbedder] load ruri-large from HuggingFaceğŸ¤—")
                token = os.getenv("HF_TOKEN")
                self.model = st.SentenceTransformer("cl-nagoya/ruri-large", token=token)
                # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹
                logger.info(f"ğŸš¦ [RuriEmbedder] save model ...")
                self.model.save(str(model_filepath))
        else:
            self.model = model

    def embed(self, text: Union[str, list[str]]) -> np.ndarray:
        """

        Parameters
        ----------
        text:
            Union[str, list[str]], ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹æ–‡å­—åˆ—

        Returns
        -------
        embedding:
             np.ndarray, åŸ‹ã‚è¾¼ã¿è¡¨ç¾. ãƒˆãƒ¼ã‚¯ãƒ³ã‚µã‚¤ã‚º 1024
        """
        embedding = self.model.encode(text, convert_to_numpy=True)
        return embedding


class RuriVoyagerSearchClient(BaseSearchClient):
    def __init__(self, dataset: pd.DataFrame, target: str,
                 index: voyager.Index,
                 model: RuriEmbedder):
        load_dotenv()
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã‚³ãƒ¼ãƒ‘ã‚¹
        self.dataset = dataset
        self.corpus = dataset[target].values.tolist()

        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
        self.embedder = model

        # Voyagerã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        self.index = index

    @classmethod
    @stop_watch
    def from_dataframe(cls, _data: pd.DataFrame, _target: str):
        logger.info("ğŸš¦ [RuriVoyagerSearchClient] Initialize from DataFrame")

        search_field = _data[_target]
        corpus = search_field.values.tolist()

        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        embedder = RuriEmbedder()

        # Ruriã®å‰å‡¦ç†
        corpus = [f"æ–‡ç« : {c}" for c in corpus]

        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹
        embeddings = embedder.embed(corpus)

        # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒ
        num_dim = embeddings.shape[1]
        logger.debug(f"ğŸš¦âš“ï¸ [RuriVoyagerSearchClient] Number of dimensions of Embedding vector is {num_dim}")

        # Voyagerã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆæœŸåŒ–
        index = voyager.Index(voyager.Space.Cosine, num_dimensions=num_dim)
        # indexã«ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿½åŠ 
        _ = index.add_items(embeddings)

        return cls(_data, _target, index, embedder)

    @stop_watch
    def search_top_n(self, _query: Union[List[str], str], n: int = 10) -> List[pd.DataFrame]:
        """
        ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹æ¤œç´¢çµæœã‚’top-nå€‹å–å¾—ã™ã‚‹

        Parameters
        ----------
        _query:
            Union[List[str], str], æ¤œç´¢ã‚¯ã‚¨ãƒª
        n:
            int, top-nã®å€‹æ•°. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 10.

        Returns
        -------
        results:
            List[pd.DataFrame], ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ
        """

        logger.info(f"ğŸš¦ [RuriVoyagerSearchClient] Search top {n} | {_query}")

        # å‹ãƒã‚§ãƒƒã‚¯
        if isinstance(_query, str):
            _query = [_query]

        # Ruriã®å‰å‡¦ç†
        _query = [f"ã‚¯ã‚¨ãƒª: {q}" for q in _query]

        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        embeddings_queries = self.embedder.embed(_query)

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°top-nã‚’ã‚¯ã‚¨ãƒªæ¯ã«å–å¾—
        result = []
        for embeddings_query in tqdm(embeddings_queries):
            # Voyagerã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¢ç´¢
            neighbors_indices, distances = self.index.query(embeddings_query, k=n)
            # é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢
            df_res = deepcopy(self.dataset.iloc[neighbors_indices])
            df_res["score"] = distances
            # ãƒ©ãƒ³ã‚¯
            df_res["rank"] = deepcopy(df_res.reset_index()).index

            result.append(df_res)

        return result
